{"organizations": [], "uuid": "edea29c020176f379f5e6918db5402fbeedc7757", "thread": {"social": {"gplus": {"shares": 0}, "pinterest": {"shares": 0}, "vk": {"shares": 0}, "linkedin": {"shares": 0}, "facebook": {"likes": 0, "shares": 0, "comments": 0}, "stumbledupon": {"shares": 0}}, "site_full": "www.cnbc.com", "main_image": "https://fm.cnbc.com/applications/cnbc.com/resources/img/editorial/2018/01/11/104941973-Orlando_2018-01-11_at_2.32.16_PM.1910x1000.png", "site_section": "http://www.cnbc.com/id/100003114/device/rss/rss.html", "section_title": "Top News &amp; Analysis", "url": "https://www.cnbc.com/2018/01/12/extremist-content-is-on-facebook-and-google-ahead-of-senate-hearing.html", "country": "US", "domain_rank": 767, "title": "Extremist content is on Facebook and Google ahead of Senate hearing", "performance_score": 0, "site": "cnbc.com", "participants_count": 1, "title_full": "", "spam_score": 0.0, "site_type": "news", "published": "2018-01-12T20:14:00.000+02:00", "replies_count": 0, "uuid": "edea29c020176f379f5e6918db5402fbeedc7757"}, "author": "John Shinal", "url": "https://www.cnbc.com/2018/01/12/extremist-content-is-on-facebook-and-google-ahead-of-senate-hearing.html", "ord_in_thread": 0, "title": "Extremist content is on Facebook and Google ahead of Senate hearing", "locations": [], "entities": {"persons": [{"name": "eric feinberg", "sentiment": "none"}], "locations": [], "organizations": [{"name": "senate", "sentiment": "negative"}, {"name": "facebook", "sentiment": "negative"}, {"name": "google", "sentiment": "negative"}, {"name": "cnbc", "sentiment": "none"}, {"name": "gipec", "sentiment": "none"}, {"name": "global intellectual property enforcement center", "sentiment": "none"}]}, "highlightText": "", "language": "english", "persons": [], "text": "CNBC.com SHARES \nEven as executives from Google and Facebook prepare to testify in front of the Senate on how they're combating extremist content, the internet giants are struggling to keep it off their sites. \nDozens of accounts on sites owned by those two companies have been used this week to promote violent attacks and recruit people to the cause of Islamic terrorism, a CNBC investigation has found. \nAll of the content that was brought to the attention of Google and Facebook by CNBC was removed within 24 hours of notification. Yet many of the posts and videos, which contained graphic images and threats of violence, had been online for days or weeks before we alerted them to it. \nIts presence on their pages underscores the enormous challenge these internet firms have in controlling content while remaining open platforms. \n\"Terrorists are using Google and Facebook technology to run what are essentially sophisticated social media marketing campaigns,\" said Eric Feinberg, co-founder of the Global Intellectual Property Enforcement Center, or GIPEC, which tracks extremist content online. \nExtremist groups are using their tools the way brand advertisers and other online marketers do, cross-promoting videos on one account with posts on other social media services. \nFacebook, YouTube and Twitter are sending representatives to Washington, D.C., on Wednesday morning to testify in front of the Senate Commerce Committee in a hearing titled \"Terrorism and Social Media: #IsBigTechDoingEnough?\" \nCNBC initially discovered some of the violent videos and posts while reporting an earlier story on Facebook users who had been locked out of their accounts by hackers. \nAfter that story was published, CNBC reported its findings to counter-terrorism officials at the U.S. Attorney's Office in San Francisco, because some of the content appeared to include coded messages about potential attacks over the Christmas holiday. \nThe office acknowledged receipt of our e-mail and said it couldn't comment further. \nWe then contacted GIPEC, a cyber-intelligence firm whose patented software finds social media activity produced by criminals and terrorists, and asked Feinberg if the group could locate more violent and extremist content. \n\"There's plenty out there if you know how to look for it,\" said Feinberg, who previously ran an online marketing and ad-tech firm based in New York. \"These companies are playing whack-a-mole\" in their fight against extremism, he said. How to make a bomb out of a 7-Up bottle \nMany of the Facebook accounts used to promote terrorist-related content appeared to have been taken over by hackers -- similar to those accounts in our prior story. \nFor example, they showed images of war-ravaged cities in the Middle East, or had flags from countries in the region, even though the profile page indicated the user was from a faraway place like Mexico or Brazil. \nThe pages also contained recent posts in Arabic while earlier posts on the profile had been exclusively in English or Spanish. \nOne page provided instructions for turning an empty soda bottle into an improvised explosive device (IED) like those used to kill and maim U.S. soldiers during conflicts in Iraq and Afghanistan. \nAccording to Google's online translation service, the Arabic text reads: \n\"An empty plastic box containing 15 yeast bags + 100 small size sharp nails. When the yeast is brewed after exposure to the sun, it will explode and the nails will spread splinters on the infidels. In the parks of the worshipers of the Cross.\" \nUsing Facebook's online reporting system, Feinberg notified the company of the page on Jan. 10, and it was soon removed. \nAnother page (which hasn't been reported) contains Islamist propaganda, including texts of speeches from Abu Musab al-Zarqawi, the former leader of al-Qaeda in Iraq who was killed by a U.S. airstrike in 2006. It's been up since at least Dec. 26. \nOf the six profiles CNBC reported to Facebook on Wednesday afternoon, all were removed within a day. \nIn response to a request for comment as to why the pages hadn't been removed earlier, a Facebook spokesperson referred us to a November blog post titled, \"Are we winning the war on terrorism online,\" from Monika Bickert, the company's global head of policy management. \n\"99% of the ISIS and Al Qaeda-related terror content we remove from Facebook is content we detect before anyone in our community has flagged it to us, and in some cases, before it goes live on the site,\" the post said. \"Once we are aware of a piece of terror content, we remove 83% of subsequently uploaded copies within one hour of upload.\" \nBickert is scheduled to appear before the Senate on Wednesday, alongside Juniper Downs, YouTube's global head of public policy and government relations, and Carlos Monje, Twitter's director of public policy and philanthropy. Promoting videos of an assassinated al Qaeda leader \nGIPEC found similar material on YouTube and Google Plus. \nOne post, which violated Google's terms of service, pointed to videos made by Anwar al-Awlaki, an American of Yemeni descent who allegedly planned terrorist attacks in Saudi Arabia before being killed by a drone strike in 2011. \nA YouTube spokesperson told CNBC that the company updated its rules last year to ban all content either promoted by or relating to individuals, including al-Awlaki, known to be members of the U.S. Department of State's list of foreign terrorist organizations. \nYouTube published a blog post in December, saying that \"98 percent of the videos we remove for violent extremism are flagged by our machine-learning algorithms\" and that 70 percent is removed within eight hours of being uploaded. \nYouTube removed more than 150,000 videos for \"violent extremism\" between June and December of last year. The company sent CNBC the following statement: \n\"In June of last year we announced steps we are taking to combat violent extremism on YouTube, including better detection and faster removal of content, more expert partners to help identify content, and tougher standards. We've made progress with these efforts, with machine learning technology flagging content to help our reviewers remove nearly five times as many videos as they previously could. We're continuing to invest heavily in people, technology and strict policies to remove this content quickly.\" \nWhile all six accounts we reported to Google were removed within 24 hours, other pages on the site still include terrorist propaganda. John Shinal Technology Reporter for CNBC.com Related Securities ", "external_links": [], "published": "2018-01-12T20:14:00.000+02:00", "crawled": "2018-01-12T20:27:09.046+02:00", "highlightTitle": ""}